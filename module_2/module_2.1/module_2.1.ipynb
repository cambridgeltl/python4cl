{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJwy3etY_kvW"
   },
   "source": [
    "## ‚ùì Pre-module quiz\n",
    "\n",
    "Why is Naive Bayes \"naive\"?\n",
    "\n",
    "A. Because it's the most basic, i.e. \"naive\" classifier we can build\n",
    "\n",
    "B. Because it \"naively\" assumes that the probabilities of features (i.e., in our case, words) are independent of each other\n",
    "\n",
    "C. Because the guy who invented it tought it was a cool name\n",
    "\n",
    "D. Because it \"naively\" assumes that the probabilities of features (i.e., in our case, words) are dependent of each other\n",
    "\n",
    "<hr>    <!-- please remember this! -->\n",
    "<details>\n",
    "  <summary>Click <b>here</b> to see the answer.</summary>\n",
    "  <p>The correct answer is B - Naive Bayes assumes that the probability of finding a certain word is independent from the probability of finding another word. So, for example, in the domain of movie reviews, it assumes that the probabilities of finding the words <code>Indiana</code> and <code>Jones</code> are not correlated, even if in practice we know that this is not the case.</p>\n",
    "\n",
    "</details> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQQUUduw_kvZ"
   },
   "source": [
    "# Python for Computational Linguists 2.1: Implementing Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daKwHNgO_kvd"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to module 2.1! In this module we will review Naive Bayes and we will write our own implementation of the algorithm. We will use it to classify some toy examples, and then we will turn to Sentiment Analysis, by training our simple model on a research dataset. We will also introduce some new concepts: the `random` module and pseudo-random number generators, cross-validation, and some new functions from `numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6O7PrvS_kvh"
   },
   "source": [
    "### Naive Bayes refresher\n",
    "\n",
    "> Note: this section borrows heavily from the Naive Bayes chapter of the lecture notes. Please refer to them or to the J&M for more details.\n",
    "\n",
    "Naive Bayes is a simple classifier based on two assumptions:\n",
    "- The **bag-of-words** assumption: word ordering doesn't matter. We represent each document in our dataset as a list of pairs $(word_i,frequency_i)$.\n",
    "- The **conditional independence** assumption: the probability of one word appearing in a sentence is by no means correlated to the occurrence of another word.\n",
    "\n",
    "These two assumptions heavily simplify our model, since they completely disregard grammar and and any domain knowledge (e.g. the `Indiana Jones` example in the pre-module quiz); but as we know now, they allow us to build a surprisingly efficient classifier.\n",
    "\n",
    "Let's quickly go through the maths of Naive Bayes. Remember that given a document $d$ and a set of classes $C$, we need to assign the document to the class $\\hat{c} \\in C$ which has the maximum *a posteriori probability*, i.e. where $\\hat{c}$ is defined as follows:\n",
    "\n",
    "$$ \\hat{c} = \\text{argmax}_{c \\in C} P(c \\mid d)$$\n",
    "\n",
    "How do we calculate $\\hat{c}$ efficiently? Well, the Bayes Rule tells us that\n",
    "\n",
    "$$ P(c \\mid d) = \\frac{P(c) \\ P(d \\mid c)}{P(d)} $$\n",
    "\n",
    "Allowing us to rewrite \n",
    "\n",
    "$$\\begin{align} \n",
    "\\hat{c} &= \\text{argmax}_{c \\in C} P(c \\mid d) \\\\\n",
    "        &= \\text{argmax}_{c \\in C} \\frac{P(c) \\ P(d \\mid c)}{P(d)}\n",
    "\\end{align}$$\n",
    "\n",
    "However, the probability $d$ is constant for each class $c$, hence we can remove it, leaving only:\n",
    "\n",
    "$$\n",
    "\\hat{c} = \\text{argmax}_{c \\in C} \n",
    "    \\underbrace{P(c)}_\\text{prior}\n",
    "    \\underbrace{P(d \\mid c)}_\\text{likelihood}\n",
    "$$\n",
    "\n",
    "Where the $prior$ is the **prior probability** of the class $c$ and the $likelihood$ is the probability of finding $d$ given the class $c$.\n",
    "\n",
    "Using words as features, we can represent $d$ as a list of words $w_1, \\dots , w_n$, hence \n",
    "\n",
    "$$\n",
    "\\hat{c} = \\text{argmax}_{c \\in C} \n",
    "    \\underbrace{P(c)}_\\text{prior}\n",
    "    \\underbrace{P(w_1, \\dots , w_n \\mid c)}_\\text{likelihood} \n",
    "$$\n",
    "\n",
    "However, $P(w_1, \\dots , w_n \\mid c)$ may be prohibitively hard to calculate, since we would need to estimate the probability of every possible combination of words. Here, the **conditional independence** assumption comes to the rescue, assuming that the probability of the words (i.e. features) are independent, allowing us to finally rewrite\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{c} &= \\text{argmax}_{c \\in C} \n",
    "       \\underbrace{P(c)}_\\text{prior}\n",
    "       \\underbrace{P(w_1 \\mid c) \\times \\dots \\times P(w_n \\mid c)}_\\text{likelihood} \n",
    "       \\\\\n",
    "       &= \\text{argmax}_{c \\in C} \n",
    "       \\underbrace{P(c)}_\\text{prior}\n",
    "       \\underbrace{\\prod_{w \\in d}{P(w \\mid c)}}_\\text{likelihood} \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ_apZnz_kvi"
   },
   "source": [
    "What does all of this mean in practice? Well, that if we have a document $d$, all we need to know to classify it is:\n",
    "- The *priors*, i.e. the probability of each class $c$\n",
    "- The *likelihoods*, i.e. the probabilities for each word $w_i$ of the document to belong to each class $c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS63pmVB_kvk"
   },
   "source": [
    "## Naive Bayes: a simple implementation\n",
    "\n",
    "Let's begin with a simple example from the Post Lecture exercises (taken from J&M-3, exercise 4.2). Given the following short movie reviews, each labeled with a genre, either comedy or action:\n",
    "\n",
    "| review                      | class  |\n",
    "|-----------------------------|--------|\n",
    "| fun, couple, love, love     | comedy |\n",
    "| fast, furious, shoot        | action |\n",
    "| couple, fly, fast, fun, fun | comedy |\n",
    "| furious, shoot, shoot, fun  | action |\n",
    "| fly, fast, shoot, love      | action |\n",
    "\n",
    "And a new document D: \n",
    "\n",
    "| review                     | class  |\n",
    "|----------------------------|--------|\n",
    "| fast, couple, shoot, fly   | ?      |\n",
    "\n",
    "We have to compute the most likely class for D.\n",
    "\n",
    "Let's start by saving our documents in some vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOi3Bhuy_kvo"
   },
   "outputs": [],
   "source": [
    "train_docs = [\n",
    "    ['fun', 'couple', 'love', 'love'],\n",
    "    ['fast', 'furious', 'shoot'],\n",
    "    ['couple', 'fly', 'fast', 'fun', 'fun'],\n",
    "    ['furious', 'shoot', 'shoot', 'fun'],    \n",
    "    ['fly', 'fast', 'shoot', 'love']]\n",
    "\n",
    "train_labels = ['comedy', 'action', 'comedy', 'action', 'action']\n",
    "test_doc = ['fast', 'couple', 'shoot', 'fly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SijxNVEO_kvx"
   },
   "source": [
    "### Computing the priors\n",
    "\n",
    "Remember what we needed to do? The first step is to compute the **priors**. Let's do that with a simple function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9nDUv_2_kvz"
   },
   "outputs": [],
   "source": [
    "# What are our classes?\n",
    "classes = set(train_labels)\n",
    "print(classes)\n",
    "\n",
    "# initialise the priors\n",
    "priors = {}\n",
    "for _class in classes:\n",
    "    priors[_class] = 0\n",
    "\n",
    "# count how many train example in each class\n",
    "for _class in classes:\n",
    "    for label in train_labels:\n",
    "        if _class == label:\n",
    "            priors[_class] += 1\n",
    "\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0WAam8n_kv8"
   },
   "source": [
    "> **<h3>üíª Try it yourself!</h3>**\n",
    "\n",
    "Now the priors are not *normalised*, i.e. we have to bring each prior in the range $[0,1]$. Can you do that in the following cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHSnm0A1_kv9"
   },
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um716nfM_kwG"
   },
   "source": [
    "<hr>    <!-- please remember this! -->\n",
    "<details>\n",
    "  <summary>Click <b>here</b> to see the answer.</summary>\n",
    "    <p><pre><code>\n",
    "for _class in classes:\n",
    "    priors[_class] = priors[_class] / len(train_labels)\n",
    "    </code></pre></p>\n",
    "\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AuK1-Hd_kwH"
   },
   "source": [
    "If you've got the priors correct, you should have $P(comedy) = 0.4$ and $P(action)=0.6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRhugs1L_kwI"
   },
   "outputs": [],
   "source": [
    "print(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHLdsavi_kwQ"
   },
   "source": [
    "> **<h3>üíª Try it yourself!</h3>**\n",
    "\n",
    "Now let's wrap everything into a function. Can you complete the cell below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02WdjzT5_kwR"
   },
   "outputs": [],
   "source": [
    "def compute_priors(labels):\n",
    "    '''\n",
    "    Computes the priors for a set of labels.\n",
    "    '''\n",
    "\n",
    "    # What are our classes?\n",
    "    classes = set(labels)\n",
    "\n",
    "    # -------------------------#\n",
    "    #      E X E R C I S E     #\n",
    "    # -------------------------#\n",
    "    # initialise the priors\n",
    "    priors = {}\n",
    "\n",
    "    # ...?\n",
    "\n",
    "    # count how many train example in each class\n",
    "    \n",
    "    # ...?\n",
    "    \n",
    "    # normalise the priors\n",
    "    \n",
    "    # ...?\n",
    "    \n",
    "    # ~      end exercise    ~ #\n",
    "    \n",
    "    return priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7W3Ep5J8_kwW"
   },
   "source": [
    "<hr>    <!-- please remember this! -->\n",
    "<details>\n",
    "  <summary>Click <b>here</b> to see the answer.</summary>\n",
    "  <p><pre><code>\n",
    "def compute_priors(labels):\n",
    "    '''\n",
    "    Computes the priors for a set of labels.\n",
    "    '''    \n",
    "    # What are our classes?\n",
    "    classes = set(labels)\n",
    "    # initialise the priors\n",
    "    priors = {}\n",
    "    for _class in classes:\n",
    "        priors[_class] = 0\n",
    "    # count how many train example in each class\n",
    "    for _class in classes:\n",
    "        for label in labels:\n",
    "            if _class == label:\n",
    "                priors[_class] += 1 \n",
    "    # normalise the priors\n",
    "    for _class in classes:\n",
    "        priors[_class] = priors[_class] / len(labels)        \n",
    "    return priors\n",
    "  </code></pre></p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzr0sUmr_kwY"
   },
   "outputs": [],
   "source": [
    "priors = compute_priors(train_labels)\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQWjpa70_kwf"
   },
   "source": [
    "### Find the vocabulary\n",
    "\n",
    "Since we need to compute the likelihoods for all words in our vocabulary, we need to find all the words in our corpus first. Let's build our vocabulary with a simple function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AA0fBu4T_kwg"
   },
   "outputs": [],
   "source": [
    "def create_vocabulary(lines):\n",
    "    '''\n",
    "    Creates a vocabulary from test.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lines: a list of lists of words\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    a set with all the words in the lines.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    words = set()\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            words.add(word)\n",
    "            \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "piKh8c9Z_kwo"
   },
   "outputs": [],
   "source": [
    "create_vocabulary(train_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qa5UuKDZ_kwu"
   },
   "source": [
    "### Computing the likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZNdLSAH_kwv"
   },
   "source": [
    "Now we need to compute the likelihoods of the words w.r.t. to each class. To do that, we can build a `dict` for each class, where `dict[word] = P(word|class)`. To do that we can slightly modify the function `create_vocab_dict` that we defined in [Module 1.4](../../module_1/module_1.4/module_1.4.ipynb). The function we defined was the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnPAawQI_kww"
   },
   "outputs": [],
   "source": [
    "def create_vocab_dict(lines):\n",
    "    '''\n",
    "    Collect vocabulary counts from text\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f_processed_arg: a list of lists of words\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a dictionary with words (str) as keys and counts(int) as values\n",
    "    vocab={\n",
    "    'SONNETS': 1\n",
    "    }\n",
    "    '''\n",
    "    vocab={}# create an empty vocabulary dictionary to store words as keys and counts as values later. \n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            if word in vocab:\n",
    "                vocab[word]+=1 # update the count for an existing word\n",
    "            else:\n",
    "                vocab[word]=1 # initilize the count for a new word\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PP2YFStX_kw2"
   },
   "outputs": [],
   "source": [
    "print(create_vocab_dict(train_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfIYzoRt_kw_"
   },
   "source": [
    "> **<h3>üíª Try it yourself!</h3>**\n",
    "\n",
    "How can we modify this function to give us the likelihoods for each class? Modify the function below, directly derived from `create_vocab_dict`, to return the likelihoods instead of the raw counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJ6JXi0M_kw_"
   },
   "outputs": [],
   "source": [
    "def compute_likelihoods(lines, vocabulary):\n",
    "    '''\n",
    "    Computes the likelihoods of words in a list of strings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lines: a list of list of words\n",
    "    vocabulary: the vocabulary of the full corpus\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a dictionary with words (str) as keys and likelihoods(floats) as values\n",
    "    vocab={\n",
    "    'SONNETS': 0.01\n",
    "    }\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # -------------------------#\n",
    "    #      E X E R C I S E     #\n",
    "    # -------------------------#\n",
    "    # create an empty vocabulary dictionary to store words \n",
    "    # as keys and counts as values later. \n",
    "    \n",
    "    likelihoods = {}\n",
    "    \n",
    "    # initialise the likelihoods\n",
    "    # hint: iterate through the vocabulary and initialise\n",
    "    # a new element of the likelihoods dict to 0\n",
    "\n",
    "    \n",
    "    \n",
    "    # ~      end exercise    ~ #    \n",
    "    \n",
    "    # Now we iterate through the lines\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            likelihoods[word] += 1 \n",
    "\n",
    "    # -------------------------#\n",
    "    #      E X E R C I S E     #\n",
    "    # -------------------------#\n",
    "    # how long are our documents?\n",
    "    total_tokens = 0\n",
    "    \n",
    "    # write your code here\n",
    "    # (hint: sum the length of the lines in total_tokens!)\n",
    "    \n",
    "    for word in likelihoods:\n",
    "        likelihoods[word] = # Write your code here\n",
    "    \n",
    "    # ~      end exercise    ~ #\n",
    "\n",
    "    return likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLOZrphY_kxI"
   },
   "source": [
    "<hr>    <!-- please remember this! -->\n",
    "<details>\n",
    "  <summary>Click <b>here</b> to see the answer.</summary>\n",
    "    <p><pre><code>\n",
    "def compute_likelihoods(lines, vocabulary):\n",
    "    '''\n",
    "    Computes the likelihoods of words in a list of strings.\n",
    "    Parameters\n",
    "    ----------\n",
    "    lines: a list of list of words\n",
    "    vocabulary: the vocabulary of the full corpus\n",
    "    Returns\n",
    "    -------\n",
    "    a dictionary with words (str) as keys and likelihoods(floats) as values\n",
    "    vocab={\n",
    "    'SONNETS': 0.01\n",
    "    }\n",
    "    '''\n",
    "    # -------------------------#\n",
    "    #      E X E R C I S E     #\n",
    "    # -------------------------#\n",
    "    # create an empty vocabulary dictionary to store words \n",
    "    # as keys and counts as values later. \n",
    "    likelihoods = {}\n",
    "    # initialise the likelihoods\n",
    "    # hint: iterate through the vocabulary and initialise\n",
    "    # a new element of the likelihoods dict to 0\n",
    "    for word in vocabulary:\n",
    "        likelihoods[word] = 0\n",
    "    # ~      end exercise    ~ #    \n",
    "    # Now we iterate through the lines\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            likelihoods[word] +=1 \n",
    "    # -------------------------#\n",
    "    #      E X E R C I S E     #\n",
    "    # -------------------------#\n",
    "    # how long are our documents?\n",
    "    total_tokens = 0\n",
    "    # write your code here\n",
    "    # (hint: sum the length of the lines in total_tokens!)\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            total_tokens +=1    \n",
    "    for word in likelihoods:\n",
    "        likelihoods[word] = likelihoods[word]/total_tokens\n",
    "    # ~      end exercise    ~ #\n",
    "    return likelihoods\n",
    "  </code></pre></p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVjCTr12_kxJ"
   },
   "outputs": [],
   "source": [
    "print(compute_likelihoods(train_docs, create_vocabulary(train_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3tkdY-S_kxR"
   },
   "source": [
    "Note that this method computes the likelihoods of the words in the whole vocabulary, irregardless of the classes. To get the likelihoods for each class we need to do as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSXTfO49_kxS"
   },
   "outputs": [],
   "source": [
    "target_class = 'action'\n",
    "target_docs = []\n",
    "vocabulary = create_vocabulary(train_docs)\n",
    "\n",
    "# enumerate builds an (index, doc) list, hence allowing\n",
    "# us to retrieve the label for each doc\n",
    "for i, doc in enumerate(train_docs):\n",
    "    if train_labels[i] == target_class:\n",
    "        target_docs.append(doc)\n",
    "        \n",
    "print(target_docs)\n",
    "print(compute_likelihoods(target_docs, vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1inBcK22_kxY"
   },
   "source": [
    "### The training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXeYGgaw_kxZ"
   },
   "source": [
    "> **<h3>üíª Try it yourself!</h3>**\n",
    "\n",
    "Now we have all the instruments to build our training function. Can you complete it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPx6Dp45_kxd"
   },
   "outputs": [],
   "source": [
    "def train_naive_bayes(documents, labels):\n",
    "    \n",
    "    classes = set(labels)\n",
    "    \n",
    "    # compute the priors\n",
    "    priors = compute_priors(labels)\n",
    "    vocabulary = create_vocabulary(documents)\n",
    "    \n",
    "    # this dict will contain the likelihoods, e.g.\n",
    "    # likelihoods['action'] = {'fast': 0.2, 'furious': 0.1...\n",
    "    likelihoods = {}\n",
    "    \n",
    "    # -------------------------#\n",
    "    #      E X E R C I S E     #\n",
    "    # -------------------------#\n",
    "    for _class in classes:\n",
    "        # get the documents belonging to each class:\n",
    "        class_docs = []\n",
    "\n",
    "        # put your code here\n",
    "        for #...\n",
    "        \n",
    "        # compute the likelihood of this class\n",
    "        likelihoods[_class] = # hint: use compute_likekihood defined above\n",
    "        \n",
    "    # ~      end exercise    ~ #\n",
    "        \n",
    "    return priors, likelihoods    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5QqYtkD_kxi"
   },
   "source": [
    "<hr>    <!-- please remember this! -->\n",
    "<details>\n",
    "  <summary>Click <b>here</b> to see the answer.</summary>\n",
    "    <p><pre><code>\n",
    "def train_naive_bayes(documents, labels):\n",
    "    classes = set(labels)\n",
    "    # compute the priors\n",
    "    priors = compute_priors(labels)\n",
    "    vocabulary = create_vocabulary(documents)\n",
    "    # this dict will contain the likelihoods, e.g.\n",
    "    # likelihoods['action'] = {'fast': 0.2, 'furious': 0.1...\n",
    "    likelihoods = {}\n",
    "    for _class in classes:\n",
    "        # get the documents belonging to each class:\n",
    "        class_docs = []\n",
    "        for i, doc in enumerate(documents):\n",
    "            if labels[i] == _class:\n",
    "                class_docs.append(doc)\n",
    "        # compute the likelihood of this class\n",
    "        likelihoods[_class] = compute_likelihoods(class_docs, vocabulary)\n",
    "    return priors, likelihoods \n",
    "    </code></pre></p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aIWjnxx_kxk"
   },
   "outputs": [],
   "source": [
    "priors, likelihoods = train_naive_bayes(train_docs, train_labels)\n",
    "\n",
    "print('Priors:')\n",
    "print(priors)\n",
    "\n",
    "print('')\n",
    "print('Likelihoods:')\n",
    "print(likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAa3kz4y_kxq"
   },
   "source": [
    "### Predict unknown classes\n",
    "\n",
    "So now we have trained our model. How can we predict the likelihood of new sentences belonging to each class? Remember from above that\n",
    "\n",
    "$$\n",
    "\\hat{c} = \\text{argmax}_{c \\in C} \n",
    "       \\underbrace{P(d)}_\\text{prior}\n",
    "       \\underbrace{\\prod_{w \\in d}{P(w \\mid c)}}_\\text{likelihood} \n",
    "$$\n",
    "\n",
    "So, to predict the class of our new sentence `fast, couple, shoot, fly`, we need to:\n",
    "- for each class `c`, we need to calculate `prob_c` by\n",
    "    - multiplying the probability of each word `w` given that class `c`\n",
    "\n",
    "Then, we'll just have to look at the maximum of our `prob_c`s. So, can we predict the class of `fast, fun, love, fly`? Let's write a function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MBJ8rbx_kxr"
   },
   "outputs": [],
   "source": [
    "def bayes_predict(document, priors, likelihoods):\n",
    "    '''\n",
    "    Predicts the label for a document given the trained\n",
    "    priors and likelihoods.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    document: the document to analyse\n",
    "    priors: the trained priors\n",
    "    likelihoods: the trained likelihoods\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The probability for each class.\n",
    "    '''\n",
    "    \n",
    "    classes_probabilities = {}\n",
    "\n",
    "    # unpack the dictionary and iterate \n",
    "    # through the priors\n",
    "    for label, prior in priors.items():\n",
    "        \n",
    "        # initialise the probability of a class to its prior\n",
    "        prob_class = prior\n",
    "        for word in document:\n",
    "            if word in likelihoods[label]:\n",
    "                # multiply the prior for the likelihood of each word\n",
    "                prob_class = prob_class*likelihoods[label][word]\n",
    "        classes_probabilities[label] = prob_class\n",
    "        \n",
    "    return classes_probabilities\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLBPW0WM_kxw"
   },
   "source": [
    "Good! Let's try it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1Z5mFi3_kxx"
   },
   "outputs": [],
   "source": [
    "document = ['fast', 'fun', 'love', 'fly']\n",
    "bayes_predict(document, priors, likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2x2iXnZG_kx2"
   },
   "source": [
    "So for this document, `comedy` is the most likely class! \n",
    "\n",
    "Now let's try with the document for the assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "In0vOLF8_kx4"
   },
   "outputs": [],
   "source": [
    "print(test_doc)\n",
    "bayes_predict(test_doc, priors, likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZfVYM2f_kx9"
   },
   "source": [
    "Now the classes are both zero! How come? Well, we didn't apply any smoothing, so obviously at some point we are multiplying the likelihoods by zero, since $P(couple \\ \\mid action) = 0$ and $P(shoot \\mid love) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpcuGGvz_kx_"
   },
   "source": [
    "### Adding 1-smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsgjY4Ck_kyA"
   },
   "source": [
    "> **<h3>üíª Try it yourself!</h3>**\n",
    "\n",
    "How can we modify `compute_likelihoods` to add 1-smoothing? Please update the function below.\n",
    "\n",
    "Note that:\n",
    "- We added a parameter (`smoothing`) to select the smoothing mode\n",
    "- You will need to change how to normalise the likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FvcUGOc_kyB"
   },
   "outputs": [],
   "source": [
    "def compute_likelihoods(lines, vocabulary, smoothing):\n",
    "    '''\n",
    "    Computes the likelihoods of words in a list of strings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lines: a list of list of words\n",
    "    vocabulary: the vocabulary of the training corpus\n",
    "    smooething: the smoothing method to use\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a dictionary with the probability for each class\n",
    "    '''\n",
    "    \n",
    "    likelihoods = {}\n",
    "\n",
    "    # populate the likelihoods\n",
    "    for word in vocabulary:\n",
    "        likelihoods[word] = 0\n",
    " \n",
    "\n",
    "    # Now we iterate through the lines to count\n",
    "    # the appearances of each word\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            likelihoods[word] +=1 \n",
    "\n",
    "    # how long are our documents?\n",
    "    total_tokens = 0\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            total_tokens +=1\n",
    "\n",
    "    # Apply smoothing, if needed\n",
    "    for word in likelihoods:\n",
    "        if smoothing == 'none':\n",
    "            \n",
    "            for line in lines:\n",
    "                for word in line:\n",
    "                    total_tokens +=1\n",
    "\n",
    "            for word in likelihoods:\n",
    "                likelihoods[word] = likelihoods[word]/total_tokens\n",
    "            \n",
    "        elif smoothing == 'add1':\n",
    "            # -------------------------#\n",
    "            #      E X E R C I S E     #\n",
    "            # -------------------------#\n",
    "            # calculate the smoothing parameter for each word.\n",
    "            smoothing_param = # ...?\n",
    "            \n",
    "            likelihoods[word] = # ...?\n",
    "            # ~      end exercise    ~ #\n",
    "        else:\n",
    "            print('Unknown smoothing!')\n",
    "            return\n",
    "\n",
    "    return likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvLuDidS_kyF"
   },
   "source": [
    "<hr>    <!-- please remember this! -->\n",
    "<details>\n",
    "  <summary>Click <b>here</b> to see the answer.</summary>\n",
    "    <p><pre><code>\n",
    "def compute_likelihoods(lines, vocabulary, smoothing):\n",
    "    '''\n",
    "    Computes the likelihoods of words in a list of strings.\n",
    "    Parameters\n",
    "    ----------\n",
    "    lines: a list of list of words\n",
    "    vocabulary: the vocabulary of the training corpus\n",
    "    smooething: the smoothing method to use\n",
    "    Returns\n",
    "    -------\n",
    "    a dictionary with the probability for each class\n",
    "    '''\n",
    "    likelihoods = {}\n",
    "    # populate the likelihoods\n",
    "    for word in vocabulary:\n",
    "        likelihoods[word] = 0\n",
    "    # Now we iterate through the lines to count\n",
    "    # the appearances of each word\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            likelihoods[word] +=1 \n",
    "    # how long are our documents?\n",
    "    total_tokens = 0\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            total_tokens +=1\n",
    "    # Apply smoothing, if needed\n",
    "    for word in likelihoods:\n",
    "        if smoothing == 'none':       \n",
    "            for line in lines:\n",
    "                for word in line:\n",
    "                    total_tokens +=1\n",
    "            for word in likelihoods:\n",
    "                likelihoods[word] = likelihoods[word]/total_tokens\n",
    "        elif smoothing == 'add1':\n",
    "            # -------------------------#\n",
    "            #      E X E R C I S E     #\n",
    "            # -------------------------#\n",
    "            # calculate the smoothing parameter for each word.\n",
    "            smoothing_param = total_tokens + len(vocabulary)\n",
    "            likelihoods[word] = (likelihoods[word] + 1)/smoothing_param\n",
    "            # ~      end exercise    ~ #\n",
    "        else:\n",
    "            print('Unknown smoothing!')\n",
    "            return\n",
    "    return likelihoods\n",
    "    </code></pre></p>\n",
    "\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tT7Fu_na_kyH"
   },
   "source": [
    "Now let's update `train_naive_bayes` to instruct it to use smoothing, and let's see if the results we obtain are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GdzIeP4_kyI"
   },
   "outputs": [],
   "source": [
    "def train_naive_bayes(documents, labels, smoothing):\n",
    "\n",
    "    classes = set(labels)\n",
    "\n",
    "    # compute the priors\n",
    "    priors = compute_priors(labels)\n",
    "    vocabulary = create_vocabulary(documents)\n",
    "\n",
    "    # this dict will contain the likelihoods, e.g.\n",
    "    # likelihoods['action'] = {'fast': 0.2, 'furious': 0.1...\n",
    "    likelihoods = {}\n",
    "\n",
    "    for _class in classes:\n",
    "        # get the documents belonging to each class:\n",
    "        class_docs = []\n",
    "\n",
    "        for i, doc in enumerate(documents):\n",
    "            if labels[i] == _class:\n",
    "                class_docs.append(doc)\n",
    "\n",
    "        # compute the likelihood of this class\n",
    "        likelihoods[_class] = compute_likelihoods(class_docs, vocabulary, smoothing)\n",
    "\n",
    "    return priors, likelihoods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfQculIr_kyO"
   },
   "outputs": [],
   "source": [
    "priors, likelihoods = train_naive_bayes(train_docs, train_labels, 'add1')\n",
    "\n",
    "print('Priors:')\n",
    "print(priors)\n",
    "\n",
    "print('')\n",
    "print('Likelihoods:')\n",
    "print(likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gGI2tRh_kyS"
   },
   "outputs": [],
   "source": [
    "bayes_predict(test_doc, priors, likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X29n2Y1d_kyZ"
   },
   "source": [
    "Great! We successfully implemented Naive Bayes in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxxV7z0e_kyc"
   },
   "source": [
    "### Improving Naive Bayes: `argmax` and log-likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDJ4r56__kyd"
   },
   "source": [
    "What we've done until now is good - but there are still a couple of open issues. \n",
    "- First, we should note that the original function of Naive Bayes is based on $\\text{argmax}$: how do we implement it in Python?\n",
    "- Then, we may note that the probabilities returned by our model are very small (i.e. in the order of $10^{-5}$), which means that for big vocabularies we may reach probabilities close to zero.\n",
    "\n",
    "While the latter may not sound like a big issue for you, unfortunately dealing with very small numbers may be problematic for a computer - as mentioned in Module 1.2, computers use [floating-point arithmetic](https://en.wikipedia.org/wiki/Floating-point_arithmetic), which in practice means that they aren't actually very good at dealing with very small or very big numbers.\n",
    "\n",
    "Actually, machines are not very good at representing any number that can't be expressed as a sum of powers of $2$. Take for example $0.1$. If we ask Python to show it, it will print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FObHawUm_kye"
   },
   "outputs": [],
   "source": [
    "0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFUfXyXN_kyi"
   },
   "source": [
    "Which looks fine. But what if we ask Python to show the first 40 decimal digits of $0.1$? That shouldn't make sense, right? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_pMoKok_kyi"
   },
   "outputs": [],
   "source": [
    "print(f'{0.1:.40f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92zHWEOC_kym"
   },
   "source": [
    "See? Under the hood Python represents 0.1 as the infinitely repeating binary fraction `0.0001100110011001100110011001100110011001100110011...`. Since we stop at 32 bits, we won't be able to exactly represent $0.1$, but we will get an approximation, i.e. the value printed in the cell above.\n",
    "\n",
    "This does not mean that our code is buggy or that Python is getting it wrong. It's just how computers work! Unfortunately, this means that, since Naive Bayes will generate very small numbers, it will be more prone to error. For this reason, we use the **log-likelihoods** instead of the actual likelihoods, i.e. we will rewrite:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{c} &= \\text{argmax}_{c \\in C} \n",
    "       \\underbrace{P(c)}_\\text{prior}\n",
    "       \\underbrace{\\prod_{w \\in d}{P(w \\mid c)}}_\\text{likelihood} \\\\\n",
    "       &= \\text{argmax}_{c \\in C} \\log(  \n",
    "       \\underbrace{P(c)}_\\text{prior}\n",
    "       \\underbrace{\\prod_{w \\in d}{P(w \\mid c)}}_\\text{likelihood} ) \\\\\n",
    "       &= \\text{argmax}_{c \\in C} \n",
    "       \\underbrace{\\log P(c)}_\\text{prior} +\n",
    "       \\underbrace{\\sum_{w \\in d}{\\log P(w \\mid c)}}_\\text{likelihood} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "To do that, we will use `numpy`, arguably Python's most popular mathematical library, which offers the function `log`.\n",
    "\n",
    "In the next cells we'll install numpy (if it's not already installed), and the we'll import it. You'll almost always find numpy imported as `np` - so if in any Python code you see something like `np.` you can assume that it's based on numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cqYN878_kyo"
   },
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RVCM5fX_kys"
   },
   "outputs": [],
   "source": [
    "# import and test with ln(e), i.e. the logarithm to the base e of e\n",
    "import numpy as np\n",
    "np.log(np.e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChYiGMkL_kyv"
   },
   "source": [
    "Numpy also offers a convenient `argmax` function. Remember that `argmax` works by selecting the *index* of the biggest element of a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5n5M0ggp_kyw"
   },
   "outputs": [],
   "source": [
    "np.argmax([0,-2,10,3])   # Remember that we use 0-based indexing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfaI3PuD_ky0"
   },
   "source": [
    "Now can wrap everything in an updated `bayes_predict_log` function, which will be the log-based version of `bayes_predict`. Can you update it yourself?\n",
    "\n",
    "> **<h3>üíª Try it yourself!</h3>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVi0BmHs_ky2"
   },
   "outputs": [],
   "source": [
    "def bayes_predict_log(document, priors, likelihoods):\n",
    "    '''\n",
    "    Predicts the label for a document given the trained\n",
    "    priors and likelihoods.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    document: the document to analyse\n",
    "    priors: the trained priors\n",
    "    likelihoods: the trained likelihoods\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    A tuple (best_class, probabilities), where the first element\n",
    "    is the name of the best class, and the second element is the dictionary of\n",
    "    the computed probabilities.\n",
    "    '''\n",
    "    \n",
    "    classes_probabilities = {}\n",
    "\n",
    "    # unpack the dictionary and iterate \n",
    "    # through the priors\n",
    "    for label, prior in priors.items():\n",
    "        \n",
    "        # -------------------------#\n",
    "        #      E X E R C I S E     #\n",
    "        # -------------------------#\n",
    "        # initialise the probability of a class to the log of its its prior\n",
    "        prob_class = # ...?\n",
    "        for word in document:\n",
    "            if word in likelihoods[label]:\n",
    "                # sum the prior with the log-likelihood of each word\n",
    "                prob_class =  # ...?\n",
    "        classes_probabilities[label] = prob_class\n",
    "    \n",
    "    # get the names of the classes\n",
    "    class_names = list(priors.keys())\n",
    "\n",
    "    # -------------------------#\n",
    "    #      E X E R C I S E     #\n",
    "    # -------------------------#\n",
    "    # complete the next line by selecting the name of the best class.\n",
    "    # hint: the probabilities are saved in the dictionaries, and\n",
    "    # you can access them by using classes_probabilities.values().\n",
    "    # note that you can use more than 1 line if you need!\n",
    "    \n",
    "    best_class = # ...?\n",
    "\n",
    "    # ~      end exercise    ~ #\n",
    "    \n",
    "    return best_class, classes_probabilities    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-UQsDyp_ky7"
   },
   "source": [
    "<hr>    <!-- please remember this! -->\n",
    "<details>\n",
    "  <summary>Click <b>here</b> to see the answer.</summary>\n",
    "  <p><pre><code>\n",
    "def bayes_predict_log(document, priors, likelihoods):\n",
    "    '''\n",
    "    Predicts the label for a document given the trained\n",
    "    priors and likelihoods.\n",
    "    Parameters\n",
    "    ----------\n",
    "    document: the document to analyse\n",
    "    priors: the trained priors\n",
    "    likelihoods: the trained likelihoods\n",
    "    Return\n",
    "    ------\n",
    "    A tuple (best_class, probabilities), where the first element\n",
    "    is the name of the best class, and the second element is the dictionary of\n",
    "    the computed probabilities.\n",
    "    '''\n",
    "    classes_probabilities = {}\n",
    "    # unpack the dictionary and iterate \n",
    "    # through the priors\n",
    "    for label, prior in priors.items():   \n",
    "        # -------------------------#\n",
    "        #      E X E R C I S E     #\n",
    "        # -------------------------#\n",
    "        # initialise the probability of a class to the log of its its prior\n",
    "        prob_class = np.log(prior)\n",
    "        for word in document:\n",
    "            if word in likelihoods[label]:\n",
    "                # sum the prior with the log-likelihood of each word\n",
    "                prob_class = prob_class + np.log(likelihoods[label][word])\n",
    "        classes_probabilities[label] = prob_class\n",
    "    # get the names of the classes\n",
    "    class_names = list(priors.keys())\n",
    "    # -------------------------#\n",
    "    #      E X E R C I S E     #\n",
    "    # -------------------------#\n",
    "    # complete the next line by selecting the name of the best class.\n",
    "    # hint: the probabilities are saved in the dictionaries, and\n",
    "    # you can access them by using classes_probabilities.values(), which\n",
    "    # can be converted to a list using list(x)\n",
    "    best_class = class_names[np.argmax(list(classes_probabilities.values()))]\n",
    "    # ~      end exercise    ~ #\n",
    "    return best_class, classes_probabilities          \n",
    "  </code></pre></p>\n",
    "\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0QBD28e_ky7"
   },
   "outputs": [],
   "source": [
    "document = ['fast', 'couple', 'shoot', 'fly']\n",
    "bayes_predict_log(document, priors, likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLWdEYHx_ky-"
   },
   "source": [
    "Good! Now the values are more reasonable and we can expect our computer to make less errors. Also, the code will run quicker, as summing typically requires less computational time than multiplying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw743DKd_ky_"
   },
   "source": [
    "### Other improvements\n",
    "\n",
    "Naturally, we could improve our Naive Bayes implementation even further. We could try different smoothing techniques, we could cache the log-likelihoods in the `likelihoods` dictionary instead of applying `np.log` every time, and so on. For now, let's just be happy with what we've done, and let's apply our code to a real world dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9rRFTGW_ky_"
   },
   "source": [
    "## Classify the *Thumbs up?* dataset\n",
    "\n",
    "We will use the data from the paper [*Thumbs up? Sentiment Classification using Machine Learning Techniques*](https://www.aclweb.org/anthology/W02-1011.pdf). The dataset consists in 1301 positive reviews and 752 negative reviews from [IMDb](https://www.imdb.com/), a large online database of facts and reviews of movies.\n",
    "\n",
    "For this part, you are **not** required to understand how the data loading and preparation works, but we encourage you to study the code anyway. After we have loaded the dataset, you will use the model you just wrote to classify it. \n",
    "The paper reports 78.7 accuracy for their Naive Bayes unigrams model; let's see if your code is able to reach this performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mbp7qlp-_kzB"
   },
   "source": [
    "### Data preprocessing\n",
    "\n",
    "In this section, we will download the data from GitHub and we'll preprocess them so that they are in the same format as above. As a reminder, training data is formatted this way:\n",
    "\n",
    "```python\n",
    "train_docs = [['fun', 'couple', 'love', 'love'],\n",
    " ['fast', 'furious', 'shoot'],\n",
    " ['couple', 'fly', 'fast', 'fun', 'fun'],\n",
    " ['furious', 'shoot', 'shoot', 'fun'],\n",
    " ['fly', 'fast', 'shoot', 'love']]\n",
    "\n",
    " train_labels = ['comedy', 'action', 'comedy', 'action', 'action']\n",
    "```\n",
    "\n",
    "Our goal is to transform the Thumb Up! dataset in this format in order to use\n",
    "the functions we defined above without any modification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7G2To1gt6Pv"
   },
   "source": [
    "Let's start by downloading the data. We use the UNIX utility `wget` for this; please be aware that if you're running this code on a Windows machine it most likely won't work, and you'll have to download the dataset by yourself and unzip it in the same folder of this notebook. If you're running this notebook locally or on Binder, you may skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbG1EoQdDGF7"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/cambridgeltl/python4cl/raw/master/module_2/module_2.2/data.zip\n",
    "!unzip -n -q data.zip -d ../module_2.2/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FSY9LFa3t4o"
   },
   "source": [
    "Let's now load the data. We will define a function that:\n",
    "\n",
    "1. Finds all the files in a directory;\n",
    "2. For each file:\n",
    "  - Loads the content of the file in a string, and\n",
    "  - Extracts all the words from the document by using `re.findall`;\n",
    "3. Finally, it returns the data as a list of lists of words, e.g.:\n",
    "\n",
    "```python\n",
    "[['hello', 'world', '...' ],   # document 1\n",
    " ['lorem', 'ipsum', '...' ],   # document 2\n",
    " ...\n",
    "]\n",
    "```\n",
    "\n",
    "You should rememeber `re.findall` from Module 1, but we encourage you to have a look at the [documentation](https://docs.python.org/3/library/re.html#re.findall)\n",
    "and play with this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "092x5LN5DGtO"
   },
   "outputs": [],
   "source": [
    "# modules needed to locate and split the data\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "def process_docs(directory):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory: a directory containing positive/negative samples from the Thumbs\n",
    "    Up! dataset.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    A list of of documents, where each document is a list of words.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    docs=[] # this will contain the documents we'll find\n",
    "\n",
    "    # walk through all files in the folder\n",
    "    for filename in os.listdir(directory):\n",
    "\n",
    "        # skip files that do not have the right extension\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            continue\n",
    "        \n",
    "        # Load the document:\n",
    "        # open the file as read only\n",
    "        with open(os.path.join(directory,filename), 'r') as f:\n",
    "          # read all text and put it in a single long string\n",
    "          doc = ''.join(f.readlines())\n",
    "          # extract all the words; \n",
    "          # re.findall finds all the substrings matching a regular expression.\n",
    "          # try the line below on some toy examples to understand how it works.\n",
    "          doc = re.findall(r'\\w+', doc)\n",
    "\n",
    "        # add the new document to the list of documents\n",
    "        docs.append(doc)\n",
    "\n",
    "    # return everything we've found\n",
    "    return docs\n",
    " \n",
    "# load positive examples\n",
    "positive_docs = process_docs(os.path.join('..', 'module_2.2', 'data', 'pos'))\n",
    "# load negative examples\n",
    "negative_docs = process_docs(os.path.join('..', 'module_2.2', 'data', 'neg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZE8539Fh5gXP"
   },
   "source": [
    "Now we have our lists of documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7yR3D6J5j79"
   },
   "outputs": [],
   "source": [
    "print('First 10 words of the first 2 positive documents:')\n",
    "print(positive_docs[0][:10])\n",
    "print(positive_docs[1][:10])\n",
    "print('First 10 words of the first 2 negative documents:')\n",
    "print(negative_docs[0][:10])\n",
    "print(negative_docs[1][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4VJcqL35kRF"
   },
   "source": [
    "Now we need to shuffle this data to obtain a training and testing set. We will \n",
    "use [`zip()`](https://docs.python.org/3/library/functions.html#zip), which \n",
    "allows us to create two list of tuples `[(positive_doc_1, 'pos'), ... (positive_doc_n, 'pos')]`\n",
    "and `[(negative_doc_1, 'neg'), ... (negative_doc_n, 'neg')]` for positive and \n",
    "negative documents respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KB8jwu5qDG3X"
   },
   "outputs": [],
   "source": [
    "all_docs = list(zip(positive_docs, ['pos'] * len(positive_docs))) +\\\n",
    "  list(zip(negative_docs, ['neg'] * len(negative_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfuVqsrB7N2K"
   },
   "source": [
    "> **<h3>üíª Try it yourself!</h3>**\n",
    "\n",
    "Have a look at the list `all_docs` in the cell below. Reassure yourself that the data is in the \n",
    "format defined above; check that the first element has a `pos` label and that the last element has a `neg` label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bu0W5H1DHA6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHebWM3C7sY_"
   },
   "source": [
    "### Shuffle the data\n",
    "\n",
    "Now we need to shuffle the data. We will use the function [`random.shuffle()`](https://docs.python.org/3/library/random.html#random.shuffle), which shuffles an array using a [pseudorandom number generator](https://en.wikipedia.org/wiki/Pseudorandom_number_generator). You don't really need to know the nuts and bolts\n",
    "of random number generation, but it's very important to stress that in computer\n",
    "science, random number are not actually that random, but they are generated by\n",
    "a function that emulates a random distribution.\n",
    "\n",
    "This function starts from a value, called seed. If we manually set the seed, we \n",
    "can ensure that the data generated by our random function is consistent \n",
    "throughout different runs, hence guaranteeing the repetibility of our experiments.\n",
    "\n",
    "> üíª Try it yourself!\n",
    "\n",
    "Look at the cell below and run it. Then, change the parameter of `random.seed()` with a value of your choice and then run it again. Now change it again to the original value (`1203`). What happens? Why? Have a very quick look at the \n",
    "Wikipedia page of  pseudorandom number generators using the link above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxuSHwGT9oeO"
   },
   "outputs": [],
   "source": [
    "random.seed(1203)\n",
    "print(random.randrange(100))  # generates a random number between 0 and 100\n",
    "print(random.randrange(100))  \n",
    "print(random.randrange(100))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5riSGTb9pOo"
   },
   "source": [
    "Now that you understand how pseudo random number generation works, let's shuffle\n",
    "the array. Note that here we instantiate a new `Random` with seed $0.42$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9YywrB1DHG7"
   },
   "outputs": [],
   "source": [
    "random.Random(.42).shuffle(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyEZPozU-Kqn"
   },
   "source": [
    "Retain the first 70% of the documents for training, and the remaining 30% for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MSRHc1CDHNI"
   },
   "outputs": [],
   "source": [
    "train_docs_thumbsup = all_docs[:int(len(all_docs)*(0.7))]\n",
    "test_docs_thumbsup =all_docs[int(len(all_docs)*(0.7)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BR3PW_-L-SAM"
   },
   "source": [
    "Now, extract the documents and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOOfi0a1Npoy"
   },
   "outputs": [],
   "source": [
    "train_txts_thumbsup = [txt for txt, _ in train_docs_thumbsup]\n",
    "train_labels_thumbsup = [label for _, label in train_docs_thumbsup]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUH2L_ab-VVU"
   },
   "source": [
    "Is the array really random? Let's have a look at the first 10 labels. Now they shouldn't be all positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3EQVKFrNpy5"
   },
   "outputs": [],
   "source": [
    "train_labels_thumbsup[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb9IcHd37uEE"
   },
   "source": [
    "### Run the model\n",
    "\n",
    "Now we have our documents and labels arrays in the same format as before. Let's feed them to our `train_naive_bayes()` function and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVXOzoVTNp7K"
   },
   "outputs": [],
   "source": [
    "tu_priors, tu_likelihoods = train_naive_bayes(train_txts_thumbsup, train_labels_thumbsup, 'add1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F82khtdX-gxP"
   },
   "source": [
    "> **<h3>üíª Try it yourself!</h3>**\n",
    "\n",
    "Very well! Now let's see how well our classifier works. In the cell below, let's\n",
    "calculate the accuracy of our algorithm.\n",
    "\n",
    "Accuracy is a metric that calculates how many times the algorithm returns the correct result. Update the cell below to obtain the accuracy of our Naive Bayes classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyw_GHGhOWvT"
   },
   "outputs": [],
   "source": [
    "correct_answers = 0\n",
    "# iterate over the documents in the test set;\n",
    "# unpack each (document, label) tuple\n",
    "for doc, true_label in test_docs_thumbsup:\n",
    "  # predict the label for the document\n",
    "  predicted_label, _ = bayes_predict_log(doc, tu_priors, tu_likelihoods)\n",
    "  # if the predicted label is the same as the true label, \n",
    "  # update the counter\n",
    "  # write your code here!\n",
    "\n",
    "# calculate the accuracy score\n",
    "accuracy = # write your code here!\n",
    "\n",
    "# print the accuracy\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cG_0f79xCiJ5"
   },
   "source": [
    "<hr>    <!-- please remember this! -->\n",
    "<details>\n",
    "  <summary>Click <b>here</b> to see the answer.</summary>\n",
    "    <p><pre><code>correct_answers = 0\n",
    "# iterate over the documents in the training set;\n",
    "# unpack each (document, label) tuple\n",
    "for doc, true_label in test_docs_thumbsup:\n",
    "  # predict the label for the document\n",
    "  predicted_label, _ = bayes_predict_log(doc, tu_priors, tu_likelihoods)\n",
    "  # if the predicted label is the same as the true label, \n",
    "  # update the counter\n",
    "  if true_label == predicted_label:\n",
    "    correct_answers += 1\n",
    "# calculate the accuracy score\n",
    "accuracy = correct_answers/len(test_docs_thumbsup)\n",
    "# print the accuracy\n",
    "print(accuracy)\n",
    "    </code></pre></p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMI1GBZ8_XkL"
   },
   "source": [
    "Great! $78.\\overline{6}\\%$ accuracy with such a simple model. The original paper obtained \n",
    "$78.7\\%$ with a similar configuration; however, we must note that their score is obtained by averaging the score of the models with three different training/test split, and they used further preprocessing steps, so the scores are not directly comparable. \n",
    "\n",
    "However, your score is very similar to the one obtained in the paper, which is \n",
    "very good! In the next module we will use another popular Python library, `scikit-learn`, to try and improve this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LskAC01y-3Le"
   },
   "source": [
    "# ‚úçÔ∏è Final Assessment\n",
    "\n",
    "The final test is aimed at obtaining the best performance out of our Naive Bayes model with little effort. You will see some advanced techniques in the next module, such as using bi-grams instead of unigrams; for now, let's focus on simpler tactics to improve our results that every machine learning practitioner should know.\n",
    "\n",
    "1. In the first part of the final test you will learn what cross-validation is, and why is it useful to build more robust models. \n",
    "2. In the second part of your final test you will experiment with *hyperparameter tuning*: you will try different values of the smoothing parameter $\\alpha$ to see how it affects the results of our algoritm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtSstCFpQMkb"
   },
   "source": [
    "## ‚úçÔ∏è Part 1 : Cross-Validation\n",
    "\n",
    "When developing machine learning models, a common problem is to tune your algorithm too heavily to perform well on a specific set of data; this problem is called **overfitting**. This happens because the model tries too hard to obtain good performance on a specific subset of your data, so it is not able to **generalise** well anymore on unseen data.\n",
    "\n",
    "In our case, we are using a training set and a test set. Even if we tune our Naive Bayes implementation very well on our test set, we have no clue on how it would perform on new, unseen data. \n",
    "\n",
    "There are several solutions to this problem; with neural networks, a typical solution is to have three sets: a training, development (or validation), and training set; we train on the training set, trying to obtain the best performance on the development set. When we are satisfied with the performance of our algorithm on the dev set, we run our model on the yet-unseen test set; since we never ran our model on this set, we will have a good idea on its ability to generalise on unseen data.\n",
    "\n",
    "However, this is not always feasible. If you don't have enough data, for example, an alternative is to use **cross-validation**. In cross-validation, you divide your corpus in a $k$ subsets, called *folds*; then, for each of the $k$ folds, we:\n",
    "\n",
    "- train the model on the other $k-1$ folds\n",
    "- evaluate the model on the current fold.\n",
    "\n",
    "We then report the average accuracy obtained on the different folds. This technique is called $k$-fold cross-validation, and it's helpful to verify that our model is able to perform well on different training/test splits, without relying to much on an arbitrary train/test split which may result in an abnormally good (or bad) model just because of chance.\n",
    "\n",
    "To learn more about cross-validation, have a look at the [documentation of scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zv2oIbX4U-8X"
   },
   "source": [
    "In this exercise, you will have to implement 5-fold cross-validation. Let's start by defining the number of folds $k$ and the seed we'll use for our experiment ([42](https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life,_the_Universe,_and_Everything_(42)))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-garfbHiQK7N"
   },
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "cross_val_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okCiX0DAVpPx"
   },
   "source": [
    "Remember that we have our documents in `all_docs`. We need to split the array in `num_folds` different subsets, i.e., our folds.\n",
    "\n",
    "We will use scikit-learn's `KFold` to do that. This helper class splits an array in $k$ folds for us, returning the indexes of the elements of each fold.\n",
    "Let'see how it works in an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhLapyiD552P"
   },
   "outputs": [],
   "source": [
    "# import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# test array\n",
    "# KFold requires that our data is in a numpy array\n",
    "# to work properly\n",
    "X = np.array(['cat','dog','bird','cow','fish'])\n",
    "\n",
    "# create the KFold object and create the splits\n",
    "kf = KFold(n_splits=num_folds)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "# iterate over the splits and show them\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "  i += 1\n",
    "  print(f'Fold {i}')\n",
    "  print(X[train_index])\n",
    "  print(X[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XejdL1MB6Blq"
   },
   "source": [
    "Good! Now, let's repeat the same process on our data. In the cell below, please:\n",
    "- Create a `KFold` object. Looking at the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), enable shuffling and use the `cross_val_seed` we defined above as seed.\n",
    "- Ask `KFold` to generate the splits, using `KFold.get_n_splits()`.\n",
    "\n",
    "> Please note that if you use different seed values here or in the previous sections of the notebooks your results may differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFx6RiABQK3m"
   },
   "outputs": [],
   "source": [
    "# -------------------------#\n",
    "#      E X E R C I S E     #\n",
    "# -------------------------#\n",
    "# create the KFold object\n",
    "kf = KFold( # ...\n",
    "# create the splits\n",
    "kf.get_n_splits(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GE_8L_7ZuYo"
   },
   "source": [
    "Great! Now let's see if we obtained the same result. Run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qkKjd-sQK0s"
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(all_docs):\n",
    "    print(train_index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTn91N9WaRZ5"
   },
   "source": [
    "The cell above **must** print ```[   0    1    2 ... 1997 1998 1999]```.\n",
    "\n",
    "Now let's run the model five times and compute the average accuracy over the runs. Complete the following cell by saving the accuracy of each fold in the list `accuracy_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6eMFAohQKv9"
   },
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "\n",
    "\n",
    "for fold_idx, (train_index, test_index) in enumerate(kf.split(all_docs)):\n",
    "\n",
    "    print(f'Running fold {fold_idx+1}...')\n",
    "    \n",
    "    # Get the current folds\n",
    "    fold_train = np.array(all_docs)[train_index]\n",
    "    fold_test = np.array(all_docs)[test_index]\n",
    "\n",
    "    # unpack sentences and labels\n",
    "    fold_txts = [txt for txt, _ in fold_train]\n",
    "    fold_labels = [label for _, label in fold_train]\n",
    "\n",
    "    # -------------------------#\n",
    "    #      E X E R C I S E     #\n",
    "    # -------------------------#\n",
    "    # run the model and save it\n",
    "\n",
    "    fold_priors, fold_likelihoods = # ... complete this line\n",
    "\n",
    "    # ~      end exercise    ~ #\n",
    "    # -------------------------#\n",
    "    #      E X E R C I S E     #\n",
    "    # -------------------------#\n",
    "    # compute the fold's accuracy and append it in the\n",
    "    # list 'accuracy_list'\n",
    "    # hint: you can mostly reuse the code for the Thumbs Up! dataset\n",
    "    \n",
    "    correct_answers = 0\n",
    "\n",
    "    # iterate over the documents in the test set (fold_test)\n",
    "    # write your code here!\n",
    "\n",
    "      \n",
    "    # calculate the accuracy score\n",
    "    accuracy = # ...\n",
    "\n",
    "    # ~      end exercise    ~ #\n",
    "    # print the accuracy\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKGfqnl05BRS"
   },
   "source": [
    "Let'a check our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o803uVkm4g6q"
   },
   "outputs": [],
   "source": [
    "print(f'Mean accuracy      : { np.mean(accuracy_list):.5f}')\n",
    "print(f'Standard deviation : { np.std(accuracy_list):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKZnlZG95KBE"
   },
   "source": [
    "If you've done everything right, the cell above should print:\n",
    "```\n",
    "Mean accuracy      : 0.81450\n",
    "Standard deviation : 0.00992\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FntNGT4O0msi"
   },
   "source": [
    "Very well! Now you've learned what cross-validation is and why is it important. Let's go on with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ol6Kgpk25R4G"
   },
   "source": [
    "## ‚úçÔ∏è Part 2: Tuning $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsjltlST1S4D"
   },
   "source": [
    "Let's continue playing with the model. Now we know that the code we wrote is quite stable, since $k$-fold cross validation shows that we obtain good results even using different training/testing splits.\n",
    "\n",
    "To improve the model a little more, we could test if changing some of its internal parameters results in an improvement. For Naive Bayes, the main parameter that we can change is the smoothing parameter $\\alpha$; for example, we may want to test what happens if, instead of 1-smoothing (i.e. $\\alpha = 1$) we use $\\alpha = 0.5$, or $\\alpha = 0.1$, or $\\alpha = 0.01$. This process is called **hyperparameter tuning**, and it's very important in modern machine learning; for example, with neural networks, once you have defined your basic architecture you will want to try what happens if you add more neurons to your network, if you change *activation function*, and so on.\n",
    "\n",
    "For now, let's concentrate on Naive Bayes. Please update `compute_likelihoods` to use a custom parameter $\\alpha$ in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6G7whpgb5WkM"
   },
   "outputs": [],
   "source": [
    "def compute_likelihoods(lines, vocabulary, alpha):\n",
    "    '''\n",
    "    Computes the likelihoods of words in a list of strings.\n",
    "    Parameters\n",
    "    ----------\n",
    "    lines: a list of list of words\n",
    "    vocabulary: the vocabulary of the training corpus\n",
    "    alpha: the alpha value to use for smoothing.\n",
    "    Returns\n",
    "    -------\n",
    "    a dictionary with the probability for each class\n",
    "    '''\n",
    "    likelihoods = {}\n",
    "    # populate the likelihoods\n",
    "    for word in vocabulary:\n",
    "        likelihoods[word] = 0\n",
    "    # Now we iterate through the lines to count\n",
    "    # the appearances of each word\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            likelihoods[word] +=1 \n",
    "    # how long are our documents?\n",
    "    total_tokens = 0\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            total_tokens +=1\n",
    "    # Apply smoothing, if needed\n",
    "    for word in likelihoods:\n",
    "          # -------------------------#\n",
    "          #      E X E R C I S E     #\n",
    "          # -------------------------#\n",
    "          # calculate the smoothing parameter for each word.\n",
    "          smoothing_param = total_tokens + len(vocabulary)\n",
    "          likelihoods[word] = # write your code here\n",
    "          # ~      end exercise    ~ #\n",
    "    return likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dhmChfm3l5B"
   },
   "source": [
    "Very well. Now let's see what happens if we call `train_naive_bayes` with different smoothing values. Run the cell below and see what happens; then, update the smoothing parameter `.1` to other values and see how `priors` and `likelihoods` change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnXN6I0q5Wgc"
   },
   "outputs": [],
   "source": [
    "priors, likelihoods = train_naive_bayes(train_docs, train_labels, .1)\n",
    "\n",
    "print('Priors:')\n",
    "print(priors)\n",
    "\n",
    "print('')\n",
    "print('Likelihoods:')\n",
    "print(likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnBFFWmZ4Tvj"
   },
   "source": [
    "Now it's time to try different smoothing parameters on the Thumbs Up! dataset. In the cell below, you have to:\n",
    "\n",
    "- Instantiate a list with the smoothing parameters we want to try; we will use $1, 0.5, 0.1, 0.01$ and an empty dictionary that will contain the accuracies for each alpha.\n",
    "- Write a `for` loop that for each $\\alpha$, \n",
    "  - runs $k$-fold cross validation on the splits defined above, and\n",
    "  - saves the average accuracy for every $\\alpha$ in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6p9paNH5b7l"
   },
   "outputs": [],
   "source": [
    "# -------------------------#\n",
    "#      E X E R C I S E     #\n",
    "# -------------------------#\n",
    "# define the alphas we will use for the experiment\n",
    "# and initialise the dictionary that will hold \n",
    "# the results\n",
    "\n",
    "alphas = # ...\n",
    "alphas_accuracy = {}\n",
    "\n",
    "# ~      end exercise    ~ #\n",
    "\n",
    "\n",
    "for alpha in alphas:\n",
    "\n",
    "  accuracy_list = []\n",
    "\n",
    "\n",
    "  for fold_idx, (train_index, test_index) in enumerate(kf.split(all_docs)):\n",
    "\n",
    "      print(f'Running alpha = {alpha}, fold {fold_idx+1}...')\n",
    "      \n",
    "      # Get the current folds\n",
    "      fold_train = np.array(all_docs)[train_index]\n",
    "      fold_test = np.array(all_docs)[test_index]\n",
    "\n",
    "      # unpack sentences and labels\n",
    "      fold_txts = [txt for txt, _ in fold_train]\n",
    "      fold_labels = [label for _, label in fold_train]\n",
    "\n",
    "      # -------------------------#\n",
    "      #      E X E R C I S E     #\n",
    "      # -------------------------#\n",
    "      # run the model and save it\n",
    "\n",
    "      fold_priors, fold_likelihoods = # ...\n",
    "\n",
    "      # ~      end exercise    ~ #\n",
    "      # -------------------------#\n",
    "      #      E X E R C I S E     #\n",
    "      # -------------------------#\n",
    "      # compute the fold's accuracy \n",
    "      \n",
    "      correct_answers = 0\n",
    "\n",
    "      # evaluate the model\n",
    "      \n",
    "      # calculate the fold's accuracy score\n",
    "      accuracy = correct_answers/len(fold_test)\n",
    "\n",
    "      # ~      end exercise    ~ #\n",
    "      # save the accuracy\n",
    "      accuracy_list.append(accuracy)\n",
    "\n",
    "  # closing for fold_idx, (train_index, test_index) in enumerate(kf.split(all_docs)):\n",
    "  \n",
    "  # -------------------------#\n",
    "  #      E X E R C I S E     #\n",
    "  # -------------------------#\n",
    "  # save the average accuracy of the run in alphas_accuracy\n",
    "  \n",
    "  alphas_accuracy[alpha] = # ...\n",
    "\n",
    "  # ~      end exercise    ~ #\n",
    "\n",
    "print('Done!')\n",
    "print('Results:')\n",
    "print(alphas_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8n5xXZ-6hrs"
   },
   "source": [
    "> Hint: to double check that what you wrote is correct, for $\\alpha = 1$ you should obtain the same results you obtained in the cross-validation exercise.\n",
    "\n",
    "Very well! If you've done everything correct, you should have noticed that decreasing values of alpha correspond to decreasing performance, so $\\alpha = 1$ is indeed the best smoothing parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSML4-ci_kzC"
   },
   "source": [
    "# Wrapping up\n",
    "\n",
    "In this notebook you should have learned how to write a simple model, how to evaluate it, and how to try to tune it to obtain the best possible performance. In the next model we will try to improve the model further by using more complex features, such as bigrams.\n",
    "\n",
    "### Additional resources\n",
    "\n",
    "- Naive Bayes chapter from [Manning, Raghavan and Sch√ºtze's Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html)\n",
    "- Python's official documentation on [floating-point arithmetics and its issues](https://docs.python.org/3/tutorial/floatingpoint.html)\n",
    "-  `scikit-learn`'s [implementation of Naive Bayes](https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/naive_bayes.py#L669)\n",
    "- Zhai and Lafferty, *A study of smoothing methods for language models applied to information retrieval*: a paper comparing different smoothing techniques for language models. [[pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.8978&rep=rep1&type=pdf)]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "module_2.2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "352px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
